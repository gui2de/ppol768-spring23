# Week 08 - Simulation Assignment 
Serenity Fan (kaf121)

## Part 1: Sampling noise in a fixed population

Create at least one figure and at least one table showing the variation in your beta estimates depending on the sample size, and characterize the size of the SEM and confidence intervals as N gets larger.  

Fully describe your results in your README.md file, including figures and tables as appropriate.  
The graph below shows the result of performing 500 simulations at subsample sizes of 10, 100, 1000, and 10,000, respectively, where the size of the fixed population is 10,000. The data generating process is given by the equation  

gen y = x1 + treatment*runiform()  

where x1 is 10,000 random draws from the standard normal distribution, and the treatment 'treatment' applied is a dummy variable adding the standard uniform distribution in noise. The noise is generated by associating a random number (again drawn from the normal distribution) to each observation, ranking observations by these random numbers in sequence, and then applying the aforementioned treatment to all observations of rank>7.  

![Beta_FixedPop_Graph](beta_graph_fixed.png)  

The table below summarizes these simulation results for the fixed population: 

| N           | mean(Beta)  | mean(SEM) | mean(CI)         | 
| ----------- | ----------- | --------- | ---------------- |
| 10          | 0.500       | 0.680     | (-1.069, 2.068)  | 
| 100         | 0.495       | 0.407     | (-0.314, 1.304)  | 
| 1000        | 0.516       | 0.395     | (-0.259, 1.290)  | 
| 10,000      | 0.506       | 0.393     | (-0.265, 1.277)  | 




## Part 2: Sampling noise in an infinite superpopulation.

Write a do-file defining a program that: (a) randomly creates a data set whose sample size is an argument to the program following your DGP from Part 1 including a true relationship an an error source; (b) performs a regression of Y on one X; and (c) returns the N, beta, SEM, p-value, and confidence intervals into r().

Using the simulate command, run your program 500 times each at sample sizes corresponding to the first twenty powers of two (ie, 4, 8, 16 ...); as well as at N = 10, 100, 1,000, 10,000, 100,000, and 1,000,000. Load the resulting data set of 13,000 regression results into Stata.

Create at least one figure and at least one table showing the variation in your beta estimates depending on the sample size, and characterize the size of the SEM and confidence intervals as N gets larger.

Fully describe your results in your README.md file, including figures and tables as appropriate.

In particular, take care to discuss the reasons why you are able to draw a larger sample size than in Part 1, and why the sizes of the SEM and confidence intervals might be different at the powers of ten than in Part 1. Can you visualize Part 1 and Part 2 together meaningfully, and create a comparison table?

Do these results change if you increase or decrease the number of repetitions (from 500)?


| Syntax      | Description |
| ----------- | ----------- |
| Header      | Title       |
| Paragraph   | Text        |